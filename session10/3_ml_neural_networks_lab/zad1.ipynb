{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mkl\n",
    "\n",
    "np.random.seed(1234)\n",
    "mkl.set_num_threads(4)\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.rcParams[\"figure.figsize\"] = [16, 9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funkcje pomocnicze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def append_ones(matrix, axis=1):\n",
    "    ones = np.ones((matrix.shape[0], 1), dtype=matrix.dtype)\n",
    "    return np.concatenate((matrix, ones), axis=axis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Propagacja sygnału, funkcja aktywacji i \"kafelki\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Propagacja sygnały przez warstwę w pelni połączoną\n",
    "def feed_forward(W, dataset, activation_fun):\n",
    "    #\n",
    "    raise Exception(\"Funkcja feed_forward nie jest zaimplementowana\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sigmoidalna funkcja aktywacji\n",
    "def sigmoid(matrix):\n",
    "    # activations = ...\n",
    "    # return activations\n",
    "    \n",
    "    raise Exception(\"Funkcja sigmoid nie jest zaimplementowana\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tiles(examples):\n",
    "    rows_count = examples.shape[0]\n",
    "    cols_count = examples.shape[1]\n",
    "    tile_height = examples.shape[2]\n",
    "    tile_width = examples.shape[3]\n",
    "    \n",
    "    space_between_tiles = 2\n",
    "    img_matrix = np.empty(shape=(rows_count * (tile_height + space_between_tiles) - space_between_tiles,  \n",
    "                                 cols_count * (tile_width + space_between_tiles) - space_between_tiles),\n",
    "                          dtype=np.float32)\n",
    "    img_matrix.fill(np.nan)\n",
    "\n",
    "    for r in range(rows_count):\n",
    "        for c in range(cols_count):\n",
    "            x_0 = r * (tile_height + space_between_tiles)\n",
    "            y_0 = c * (tile_width + space_between_tiles)\n",
    "            img_matrix[x_0:x_0 + tile_height, y_0:y_0 + tile_width] = examples[r, c]\n",
    "    \n",
    "    return img_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram aktywacji i filtry w pierwszej warstwie sieci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Rbm:\n",
    "    def __init__(self, visible_size, hidden_size, learning_rate):\n",
    "        self.visible_size = visible_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.W = np.random.normal(scale=0.01, size=(visible_size+1, hidden_size+1)).astype(np.float32)\n",
    "        self.W[:, -1] = 0.0\n",
    "        self.W[-1, :] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import mnist\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "\n",
    "with open(\"./lab1_rbm.pickle.dat\", \"rb\") as f:\n",
    "    rbm = pickle.load(f)\n",
    "\n",
    "DATASET_SIZE = 512\n",
    "DIGIT_SIZE = 28\n",
    "mnist_dataset = mnist.test_images().astype(np.float32)\n",
    "np.random.shuffle(mnist_dataset)\n",
    "mnist_dataset = np.reshape(mnist_dataset[:DATASET_SIZE] / 255.0, newshape=(DATASET_SIZE, DIGIT_SIZE*DIGIT_SIZE))\n",
    "\n",
    "mnist_dataset = append_ones(mnist_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Histogram wartości aktywacji neuronów\n",
    "activations = feed_forward(rbm.W, mnist_dataset, sigmoid)\n",
    "mean_activations = np.mean(activations, 1)\n",
    "sns.distplot(mean_activations, bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Filtry w pierwszej warstwie sieci\n",
    "filters = np.reshape(np.transpose(rbm.W)[:-1, :-1], newshape=(16, -1, 28, 28))\n",
    "filters = np.clip(filters, -1.0, 1.0)\n",
    "\n",
    "img = tiles(filters)\n",
    "plt.matshow(img, cmap='gray', interpolation='none')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
