<!doctype html>
<html>
<head>
    <title>Klaster Spark - zadania</title>
    <meta charset="utf-8">
</head>
<body>
<h3>Klaster Spark</h3><h4>Korzystanie z klastra Sparka na AWS</h4><p>Opis znajduje się w Notebooku:&nbsp;</p><h4>Zadania</h4><h5>1. Korzystanie z klastra dla małych danych</h5><p>Proszę wykonać następujące zapytania z wykorzystaniem danych z OpenAQ:&nbsp;https://registry.opendata.aws/openaq/</p><p></p><ol><li>Znaleźć miasto, w którym najniższe zanieczyszczenie w danym okresie jest największe spośród wszystkich miast<br></li><li>Ranking miast pod względem liczby dni w roku, w których poziom jest wyższy niż X<br></li><li>Ranking krajów pod względem średniego zanieczyszczenia<br></li><li>Średnie zanieczyszczenie w miastach: na wykresie/mapie<br></li></ol><p>Uwaga 1: zapytania wykonujemy najpierw na małych danych (1 dzień).&nbsp;</p><p>Uwaga 2: warto ograniczyć dane do Europy, na podstawie współrzędnych geograficznych lub do Polski (na podstawie symbolu kraju)</p><h5>2. Korzystanie z klastra dla dużych danych</h5><p></p><ol><li>Proszę wykonać zadanie 1 dla danych z całego miesiąca. Zmierzyć czas wykonania.<br></li><li>Zwiększyć klaster do 2, 4, 8, 16 instancji workerów i zmierzyć czasy wykonania</li><li>Narysować wykresy przyspieszenia i efektywności (speedup, efficiency)</li></ol><h5>3. Zadanie z Big Data</h5><p></p><ol><li>Proszę wykonać przykładowe zapytanie dla danych z całego roku 2018.</li></ol><p></p><p></p><p></p>
</body>
</html>